{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Homework 4: Apply k-NN and Linear Regression\n",
        "DATA 202 FA19 @ Calvin University\n",
        "\n",
        "**Due**: Thursday October 10 @ 11:59pm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Purpose\n",
        "\n",
        "In this homework, you will apply what you learned in Homework 3 in a different situation. You'll also use the same tools to fit a linear regression, and compare and contrast the two modeling approaches.\n",
        "\n",
        "After completing this assignment, you should be more comfortable with:\n",
        "\n",
        "* The concepts of training and testing data\n",
        "* The similarities and differences between Nearest-Neighbors regression and Linear Regression\n",
        "* The sklearn regression API\n",
        "* Working with Pandas DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tasks\n",
        "\n",
        "The instructions below will guide you through completing this assignment. A few strategic recommendations:\n",
        "\n",
        "* Read through the whole thing before starting to get an overview\n",
        "* Identify something that's unclear, or some knowledge you might be missing, and ask a question on Piazza.\n",
        "* As much as possible, try and stick to the hints and functions we import at the top of the homework, as those are the ideas and tools the class supports and is aiming to teach.\n",
        "* **Avoid** getting stuck on one part for a long time. Take breaks.\n",
        "* Try not to Google anything or copy code off the Internet. You should be able to do this referring only to:\n",
        "  - your hw3 \"notes\" (and maybe your solutions)\n",
        "  - the Pandas documentation (remember the shift-tab-tab trick in Jupyter Notebook, and the links in the Help menu\n",
        "  - the Data 100 textbook\n",
        "* Check your understanding as you go. Master this.\n",
        "\n",
        "\n",
        "Before you begin, please fill out [THIS GOOGLE FORM](https://docs.google.com/forms/d/e/1FAIpQLSdS1pi1AkbnnvXTwiVyz-BoB3yWtmysATlMVKDZcZEjV1RJJg/viewform?usp=sf_link)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Criteria for Success\n",
        "\n",
        "A successful submission will have these characteristics:\n",
        "\n",
        "* All questions are answered\n",
        "* All code is correct and succinct. (There should be no extraneous code.)\n",
        "* Short answers should be *correct* (answering all parts), *clear* (easy to understand), and *concise*. Bullet points are fine if each point is a complete thought. (Use no more than 3 or 4 lines of text.)\n",
        "* Where possible, free response answers should connect the *data* with the *real world*.\n",
        "* Plots should be well documented: we will expect appropriate titles, axis labels, legends, etc. **The following question serves as a good guideline on what is \"enough\": If I directly downloaded the plot and viewed it, would I be able to tell what was being visualized without knowing the question?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6UuF87zGc8te"
      },
      "source": [
        "### How to Submit\n",
        "\n",
        "Fill in the following information within this cell:\n",
        "\n",
        "* **I worked with**:\n",
        "* **One question I asked (either of another person, on Piazza, or of the Internet) was**:\n",
        "* **This assignment actually took me**: \n",
        "* **The hardest part was**: \n",
        "\n",
        "Then:\n",
        "\n",
        "* Rename this file to `hw4_username.ipynb`, replacing `username` with your Calvin username\n",
        "* Run `Kernel->Restart and Run All` and check that everything works.\n",
        "* Submit your `ipynb` file (only) to Moodle.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 1: Setup\n",
        "\n",
        "You started working with the Capital Bike Share dataset in Homework 2. We're going to extend our work there to try to predict ridership.\n",
        "\n",
        "Our basic goal will be to try to predict ridership in 2012 based on ridership data in 2011. So the 2011 data will be our *training set* and the 2012 data will be our *test set* (aka *held-out* data or sometimes *validation* data).\n",
        "\n",
        "First, we'll load up the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "%matplotlib inline\n",
        "\n",
        "# Set some display settings.\n",
        "sns.set(context='notebook')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "hourly_counts_orig = pd.read_csv('data/hour.csv')\n",
        "hourly_counts_orig.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1.1: Renaming\n",
        "Some of those column names are pretty awful. It's as if the authors didn't know that they could (usually) tab-complete column names! Let's fix a few of them up. Use the `rename` method on the `hourly_counts_orig` DataFrame to rename the following columns:\n",
        "\n",
        "old | new\n",
        "---|----\n",
        "dteday | date\n",
        "hr | hour\n",
        "mnth | month\n",
        "cnt | riders\n",
        "\n",
        "Store the result in a variable called `hourly_counts` (keeping `_orig` untouched).\n",
        "\n",
        "*Try not to Google this. Look in the [Pandas user guide](https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html#basics-rename).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert hourly_counts['hour'].max() == 23\n",
        "assert hourly_counts['riders'].max() > 900"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1.2: Train-Test Split\n",
        "We're going to use 2011 as the training set and 2012 as the test set. **Make two new DataFrames based on `hourly_counts`, one called `train` containing only data from 2011, and one called `test` containing only 2012 data.**\n",
        "\n",
        "The dataset already has a column, `yr`, which tells the two apart. I won't tell you what the values in the `yr` column mean; you can figure them out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "hourly_counts.yr.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert train['date'].iloc[0] == '2011-01-01'\n",
        "assert test['date'].iloc[0] == '2012-01-01'\n",
        "assert all(train['date'].str.startswith('2011'))\n",
        "assert all(test['date'].str.startswith('2012'))\n",
        "assert len(train) + len(test) == len(hourly_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1.3: Sizes\n",
        "1. How many observations are in the training set and the test set?\n",
        "2. How many observations should there be? How many are missing?\n",
        "3. Can you come up with a guess of why some observations might be missing? (there are masy possible answers here)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*your answer here*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 2: Predicting Ridership using a Single Predictor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What would be some simple predictors of ridership? One that comes to mind is temperature: sometimes it's just too cold to bike. Let's try using temperature to predict ridership."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2.1\n",
        "The following code makes a scatterplot that attempts to show how ridership depends on temperature.\n",
        "\n",
        "1. What is one observation you can make about this relationship based on this graph? Use \"real world\" language as much as you can.\n",
        "2. What's one thing that's unclear about this graph? (What makes the relationship hard to see?) What's one thing you might change to improve it? (You don't have to actually make that change.)\n",
        "\n",
        "*Note*: Temperature was \"normalized\" (we'll discuss more about this shortly). Here's how the dataset page says they computed it:\n",
        "\n",
        "```\n",
        "- temp : Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)\n",
        "- atemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(train['temp'], train['riders'], s=.3)\n",
        "plt.xlabel(\"Normalized temperature\")\n",
        "plt.ylabel(\"# Riders\")\n",
        "plt.title(\"Ridership by Temperature\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2.2\n",
        "Fit a Nearest-Neighbors model to the training data, using the same predictor (`temp`) and response (`riders`). Plot the model's predictions on top of a scatterplot of the data.\n",
        "\n",
        "*Note* This should be extremely familiar from hw3. If you need to copy-paste the new-axis stuff that's fine, but try to do the k-NN and plotting from just your notes.\n",
        "\n",
        "*Hint*: Try `train[['temp']].values`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Extract the training data\n",
        "Make variables `train_x` and `train_y` containing the data for this prediction problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert train_x.ndim == 2\n",
        "assert train_x.shape[1] == 1\n",
        "assert train_y.ndim == 1\n",
        "assert len(train_x) == len(train_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Train the k-NN model on the training data\n",
        "Call it `knn`. Use 5 neighbors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert knn.n_neighbors == 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Evaluate what the model predicts for each temperature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make variables called `x` and `y_predicted`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Make the plot.\n",
        "Remember to label it. Try to make both the predictions and the raw data show up clearly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2.3\n",
        "What mean squared error does the 5-NN model get when predicting on the training data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Make a prediction for each training-set observation.\n",
        "Call it `train_y_predicted`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here (one line)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Write a function to compute the mean squared error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mean_squared_error(y_true, y_predicted):\n",
        "    \"\"\"Compute the MSE of a model that predicts y_predicted when the true answer was y_true.\n",
        "    \"\"\"\n",
        "    assert len(y_true) == len(y_predicted)\n",
        "    # Your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert np.isclose(\n",
        "    mean_squared_error(np.array([0, 0]), np.array([0, 2])),\n",
        "    2.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Check your MSE function against sklearn's MSE function.\n",
        "Turns out sklearn's `metrics` module gives us what we need already. We'll use it going forward. You can just run this code, but read it to understand what it's doing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert np.allclose(\n",
        "    mean_squared_error(train_y, train_y_predicted),\n",
        "    metrics.mean_squared_error(y_true=train_y, y_pred=train_y_predicted))\n",
        "\n",
        "assert mean_squared_error is not metrics.mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Compute the training MSE.\n",
        "Label the printout so it's understandable without looking at the code or instructions. Use sklearn's `metrics.mean_squared_error` function.\n",
        "\n",
        "**What units is the MSE in? Include that in your printout.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2.4\n",
        "What MSE does this same 5-NN model get on the test data? How does that compare with the training MSE?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3: Linear Regression\n",
        "Now we're going to try a linear regression on the same task: predicting ridership from temperature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 3.1\n",
        "Fit a linear regression (\"ordinary least squares\") model to the training data, using the same predictor (`temp`) and response (`riders`). Plot the model's predictions on top of a scatterplot of the data.\n",
        "\n",
        "You can reuse variables you made in Question 2, like `x` and `train_x`, if they're still appropriate.\n",
        "\n",
        "Use `LinearRegression`, which we imported from `sklearn` at the top. Call the model `linreg`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 3.2\n",
        "Make the plot in Question 3.1 again, still using the same linear model, but implementing the math on your own instead of using `linreg.predict`.\n",
        "\n",
        "The following expressions extract the parameters that sklearn computed for the linear model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Intercept:\", linreg.intercept_)\n",
        "print(\"Coefficients:\", linreg.coef_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Complete this function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def my_linreg_predict(x, linreg):\n",
        "    \"\"\"Return the array of predicted values for each x value, using the supplied linreg model.\n",
        "    \"\"\"\n",
        "    # Your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the graph again. Labeling not necessary this time.\n",
        "# Your code here.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Question 3.3\n",
        "What mean squared error does the linear regression model get when predicting on the training data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3.4\n",
        "What MSE does this same linear regression model get on the test data? How does that compare with its training MSE?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3.5\n",
        "Compare and contrast the 5-NN model and the linear regression model.\n",
        "\n",
        "* In what ways is the 5-NN model better?\n",
        "* In what ways is the Linear Regression model better?\n",
        "* What sort of a pattern does it look like the data actually has? Do you think a linear model is a good fit for it?\n",
        "* Which one would you use, if you had to pick? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 4\n",
        "The comparison we made was between a 5-NN and a linear regression model. What if we had chosen a different $k$?\n",
        "\n",
        "## Question 4.1\n",
        "\n",
        "Assuming you have named all of your variables as requested, the code below should make a plot very similar to one you made in hw3. We also added a horizontal line for the linear regression's testing MSE.\n",
        "\n",
        "1. What do you notice about this graph?\n",
        "2. What value of $k$ should we choose?\n",
        "3. Would you answer Question 3.5 any differently if using that chosen value of k?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_neighbors_vals = list(range(5, 500, 5))\n",
        "training_mses = []\n",
        "testing_mses = []\n",
        "for n_neighbors in n_neighbors_vals:\n",
        "    knn = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
        "    knn.fit(train_x, train_y)\n",
        "    training_mses.append(metrics.mean_squared_error(train_y, knn.predict(train_x)))\n",
        "    testing_mses.append(metrics.mean_squared_error(test_y, knn.predict(test_x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(n_neighbors_vals, training_mses, label=\"k-NN\")\n",
        "plt.hlines(\n",
        "    metrics.mean_squared_error(y_true=train_y, y_pred=linreg.predict(train_x)),\n",
        "    n_neighbors_vals[0], n_neighbors_vals[-1], label=\"Linear Regression\")\n",
        "plt.xlabel(\"k (# neighbors)\")\n",
        "plt.ylabel(\"mean squared error\");\n",
        "plt.title(\"Training Set MSEs, varying # neighbors\")\n",
        "plt.legend()\n",
        "plt.xlim(n_neighbors_vals[0], n_neighbors_vals[-1]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "if False: # Run this only once you've answered 4.1\n",
        "    plt.plot(n_neighbors_vals, testing_mses, label=\"k-NN\")\n",
        "    plt.hlines(\n",
        "        metrics.mean_squared_error(y_true=test_y, y_pred=linreg.predict(test_x)),\n",
        "        n_neighbors_vals[0], n_neighbors_vals[-1], label=\"Linear Regression\")\n",
        "    plt.xlabel(\"k (# neighbors)\")\n",
        "    plt.ylabel(\"mean squared error\");\n",
        "    plt.legend()\n",
        "    plt.xlim(n_neighbors_vals[0], n_neighbors_vals[-1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Your answer here*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}