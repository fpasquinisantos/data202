---
title: "Feature Engineering"
author: "K Arnold"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    self_contained: FALSE
    lib_dir: libs
    nature:
      ratio: "16:9"
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE, message=FALSE}
source("../slides-common.R")
slideSetup()
knitr::opts_chunk$set(echo = TRUE)
```

## Feedback

.pull-left[
**Good**

* Coding together
* Motivating: lab, hw, visualizations, applications
* Connecting with me (and, sometimes, connecting with others)

(Oops, accidentally asked these questions twice!)
]

.pull-right[
**To improve**

* Structure in class
* Lots of different things to do. So:
  * Check-in quizzes open at beginning of class. Will leave 1 min at end to fill out.
  * Flexible teamwork: each cohort will get 5 repos. Split up as you desire.
  * Goal: no required teamwork outside of class time
* Support outside of class
  * Many students have reached out on Teams at all hours.
  * Feedback / grading
]

---

## Logistics

* Project: finish next week
  * Delve into the *data*: source? assumptions?
  * Delve into the vis *design*: which retinal variables chosen for which data variables, and why?
* Midterm Quiz: Quiz 8 open for a week, similar structure to Quiz 7
* Review sessions on Teams: ask about any past assignment!

Plan:

* Mon: decision tree regression
* Wed: decision tree classification
* Fri: lab about **overfitting**

---

## General Hints

* Visualization:
  * What *glyph* represents each *observation*? 
  * What *attributes*/aesthetics does that glyph have? (x, y, width, color, ...)
  * What *controls* each aesthetic? ("each party has a *y* position", ...)
* Wrangling
  * What does the *input* look like? (Translate the first row into a data sentence in English.)
  * What does the *output* need to look like? (Again, write a sentence.)
  * What *sequence of steps* needs to happen? (e.g., `filter-group_by-summarize-arrange`)
* Modeling
  * What *quantity* are you trying to predict?
  * What *error measure* will tell you the prediction is good / bad?
  * What *features* can help you make that prediction?

---

## Q&A

> Why don't we just use `lm(y ~ x)` like other stats classes?

* We'll be using many other kinds of models; we're starting with linear models because many people have seen them before.
* `tidymodels` gives a unified interface to lots of different models
* Formulas support some kinds of feature engineering (e.g., `y ~ x1 * x2`) but limited.

> Can we use categorical (nominal) variables in predictive models?

Yes, we'll do that today!

> Can we see that dashboard?

<https://rsconnect.calvin.edu/mi-covid/>

---

## Recipes

### Why

Recipes can help us:

* Add expressive power (like conditional logic) to simple models
* Make the model more (or less!) understandable

### What

A **recipe** is a data processing *pipeline* (like `%>%`) where the steps can be "smart".

> Smart?

like learning what range the data values fall in, to be able to scale them.

---

class: center, middle

# Setup

---

```{r}
library(tidymodels)
data(ames, package = "modeldata")
ames <- ames %>% 
  filter(Gr_Liv_Area < 4000, Sale_Condition == "Normal") %>% 
  mutate(across(where(is.integer), as.double))
```

```{r train-test-split}
set.seed(10) # Seed the random number generator
ames_split <- initial_split(ames, prop = 2/3) # Split our data randomly
ames_train <- training(ames_split)
ames_test <- testing(ames_split)
```

We'll use one example home from the test set.

```{r example-home}
example_home <- ames_test %>% slice(1)
example_home %>% select(Gr_Liv_Area, Sale_Price)
```

---

class: center, middle

# Recipes

---

```{r}
ames_recipe_1 <- 
  recipe(Sale_Price ~ Gr_Liv_Area + Latitude + Longitude, data = ames_train) %>% 
  prep()
ames_recipe_1 %>% summary()
ames_recipe_1 %>% bake(new_data = ames_train)

```

---

## Workflows

`workflow` = `recipe` + `model`

```{r}
workflow1 <- workflow() %>%
  add_model(linear_reg() %>% set_engine("lm")) %>% 
  add_recipe(ames_recipe_1)
```

Workflows can `fit` and `predict`. First let's `fit` it on our training data...

```{r fit-workflow1-on-train}
fitted_workflow1 <- fit(workflow1, data = ames_train)
```

Now let's see what it predicts for our example home. (write this down)

```{r predict-workflow1-on-example}
fitted_workflow1 %>% predict(example_home)
```

---

class: center, middle

## Let's peek inside the model...

---

```{r unscaled-latlong}
fitted_workflow1 %>% 
  tidy() %>%
  filter(term != "(Intercept)") %>% 
  ggplot(aes(x = estimate, y = term)) + geom_col()
```

---

class: center, middle

## Feature Engineering 101: Scaling the features

---

## The features have very different ranges


```{r}
ames_train %>% 
  select(Gr_Liv_Area, Latitude, Longitude) %>% 
  summary()
```

So the coefficients need to have very different scales to have a similar effect.

```{r}
tidy(fitted_workflow1) %>% select(1:2)
```

---

class: center, middle

## Solution: scale the features to all be in the same range


---

```{r}
ames_recipe_2 <- 
  recipe(Sale_Price ~ Gr_Liv_Area + Latitude + Longitude, data = ames_train) %>% 
  step_range(all_numeric(), -all_outcomes(), min = 0, max = 1) %>% #<<
  prep()
ames_recipe_2 %>% bake(new_data = ames_train) %>% summary()

fitted_workflow2 <- workflow() %>%
  add_model(linear_reg() %>% set_engine("lm")) %>% 
  add_recipe(ames_recipe_2) %>% 
  fit(data = ames_train)
```

```{r}
fitted_workflow2 %>% predict(example_home)
```

---

```{r scaled-latlong}
fitted_workflow2 %>% 
  tidy() %>%
  filter(term != "(Intercept)") %>% 
  ggplot(aes(x = estimate, y = fct_reorder(term, estimate))) + geom_col()
```

---

## Recipe steps remember things from training data

* Remember we had: `step_range(..., min = 0, max = 1)`
* `output = (input - input_min) / (input_max - input_min)`
* It had to remember `input_min` and `input_max`!

**Question**: Suppose we apply this recipe to the **test set**. *What do
we expect the minimum and maximum values to be* for `Gr_Liv_Area` etc.?

--

```{r}
fitted_workflow2 %>%
  pull_workflow_prepped_recipe() %>% 
  bake(new_data = ames_test) %>% #<<
  summary()
```


---

## What computations can a linear model do?

* *Add* up terms.
* Each term: *multiply* a number by a constant.

.pull-left[
```{r coefs-from-fitted-model}
intercept <- 15793
coef_living_area <- 108
```


```{r}
intercept + coef_living_area * 1610
```
]

.pull-right[
```{r price-vs-liv-area, out.width="100%"}
ggplot(ames, aes(x = Gr_Liv_Area, y = Sale_Price)) +
  geom_point() +
  geom_hline(yintercept = example_home$Sale_Price, color = "red") +
  geom_vline(xintercept = example_home$Gr_Liv_Area, color = "red") +
  geom_point(data = example_home, color = 'red', size = 5) +
  geom_function(fun = function(x) intercept + coef_living_area * x, color = "blue")
```
]

---

## Do remodeled homes sell for more?

`Year Remod/Add`: Remodel date *(same as construction date if no remodeling or additions)*
(from dataset documentation)

```{r remodeled, out.width = "70%"}
ames %>% 
  mutate(remodeled = Year_Remod_Add != Year_Built) %>% #<< 
  ggplot(aes(x = Gr_Liv_Area, y = Sale_Price, color = remodeled)) +
  geom_point() +
  geom_smooth(method = "lm")
```


---

## Conditional Logic: Simple Conditions

How could a *linear model* treat remodeled homes differently from non-remodeled?

```
if remodeled:
  Sale_Price = intercept_remodeled + coef_sqft * Gr_Liv_Arera
else:
  Sale_Price = intercept_other + coef_sqft * Gr_Liv_Arera
```

--

### Solution: "**dummy encoding**"

```
Sale_Price = 
   intercept_other 
   + coef_remodeled * (1 if remodeled)
   + coef_sqft      * Gr_Liv_Area
```

---

```{r}
ames_train_2 <- ames_train %>% 
  mutate(remodeled = case_when(
    Year_Built == Year_Remod_Add ~ "no",
    TRUE                         ~ "yes") %>%
    as_factor()
  )
```

.small[

```{r}
ames_recipe_3 <- 
  recipe(Sale_Price ~ Gr_Liv_Area + remodeled, data = ames_train_2) %>% 
  step_dummy(remodeled) %>% #<<
  step_range(all_numeric(), -all_outcomes(), min = 0, max = 1) %>%
  prep()
ames_recipe_3 %>% bake(new_data = ames_train_2) %>% head(10) %>% knitr::kable(format = "html")
```
]
