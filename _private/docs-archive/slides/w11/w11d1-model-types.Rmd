---
title: "Different Types of Models"
author: "DATA 202 21FA"
output:
  xaringan::moon_reader:
    css: ["xaringan-themer.css", "slides.css"]
    lib_dir: libs
    self_contained: false
    nature:
      ratio: "4:3"
      highlightLines: true
      highlightStyle: solarized-light
      countIncrementalSlides: false
---


```{r setup, include=FALSE, code=xfun::read_utf8('../slide-setup.R')}
```

```{r setup2, include=FALSE}
if (interactive()) source('../slide-setup.R')
library(tidyverse)
library(tidymodels)
library(rpart.plot)

sweep_model <- function(model, var_to_sweep, sweep_min, sweep_max, ...) {
  X <- expand_grid(!!enquo(var_to_sweep) := seq(sweep_min, sweep_max, length.out = 500), ...)
  model %>% 
    predict(X) %>% 
    bind_cols(X)
}

add_predictions <- function(data, model, variable_name = ".pred", model_name = deparse(substitute(model))) {
  model %>%
    predict(data) %>%
    rename(!!enquo(variable_name) := .pred) %>%
    mutate(model = model_name) %>%
    bind_cols(data)
}
```

.small-code[
```{r load-and-subset-data}
data(ames, package = "modeldata")
ames_all <- ames %>%
  filter(Gr_Liv_Area < 4000, Sale_Condition == "Normal") %>%
  mutate(across(where(is.integer), as.double)) %>%
  mutate(Sale_Price = Sale_Price / 1000)
rm(ames)
```

```{r train-test-split}
metrics <- yardstick::metric_set(mae, mape, rsq_trad)

set.seed(10) # Seed the random number generator
ames_split <- initial_split(ames_all, prop = 2 / 3)
ames_train <- training(ames_split)
ames_test <- testing(ames_split)
```

```{r echo=FALSE}
lat_long_grid <- expand_grid(
  Latitude  = modelr::seq_range(ames_train$Latitude,  n = 200, expand = .05),
  Longitude = modelr::seq_range(ames_train$Longitude, n = 200, expand = .05),
)
```


```{r plot-util, echo=FALSE}
show_latlong_model <- function(dataset, model, model_name = deparse(substitute(model))) {
  ggplot(dataset, aes(x = Longitude, y = Latitude)) +
    geom_raster(
      data = lat_long_grid %>% add_predictions(model),
      mapping = aes(fill = .pred)
    ) +
    geom_point(color = "black", size = .75) +
    geom_point(aes(color = Sale_Price), size = .5) +
    scale_color_viridis_c(aesthetics = c("color", "fill")) +
    coord_equal() +
    labs(title = model_name)
}
```

```{r train-model2}
model2 <-
  decision_tree(mode = "regression", tree_depth = 30) %>%
  fit(Sale_Price ~ Latitude + Longitude, data = ames_train)
```
]

---

## Objectives

What type of model for what type of data?

- Describe how a Random Forest makes predictions
- Describe how a linear model makes predictions
- Compare and contrast linear and tree models

Reference: [Fitting and Predicting with `parsnip`](https://parsnip.tidymodels.org/articles/articles/Examples.html)

---

class: center, middle

# Random Forests

---

## Why?

```{r declare-cv, echo=FALSE}
ames_resamples <- ames_train %>% vfold_cv(v = 10)
```

```{r declare-all-models, echo=FALSE, cache=TRUE}
all_models <- tribble(
  ~model_name, ~spec,
  "tree1",    decision_tree(mode = "regression", tree_depth = 2),
  "tree2",    decision_tree(mode = "regression", tree_depth = 30),
  "tree3",    decision_tree(mode = "regression", cost_complexity = 1e-6, min_n = 2),
  "forest1",  rand_forest(mode = "regression")
)
```

```{r sample-all-models, echo=FALSE, cache=TRUE}
models_with_samples <- all_models %>% 
  rowwise() %>% 
  mutate(samples = list(
    spec %>% fit_resamples(
      Sale_Price ~ Latitude + Longitude,
      resamples = ames_resamples,
      metrics = metric_set(mae))))
```

```{r last-fit, echo=FALSE, message=FALSE}
test_predictions <- 
  all_models %>% 
  rowwise(model_name) %>% 
  # Fit on all training data
  mutate(fit_on_all_training_data = list(spec %>% fit(Sale_Price ~ Latitude + Longitude, data = ames_train))) %>% 
  # Test on test set
  summarize(ames_test %>% add_predictions(fit_on_all_training_data) %>% mae(truth = Sale_Price, estimate = .pred))
```

```{r compare-models-traintest, echo=FALSE, message=FALSE, out.width="100%"}
models_with_samples %>% 
  rowwise(model_name) %>% 
  summarize(collect_metrics(samples, summarize = FALSE), .groups = "drop") %>% 
  bind_rows(
    train = .,
    test = test_predictions,
    .id = "assessment_data"
  ) %>% 
  mutate(assessment_data = as_factor(assessment_data)) %>% 
  ggplot(aes(x = as_factor(model_name), y = .estimate, color = assessment_data)) +
  geom_boxplot() +
  labs(x = "Model name", y = "Mean absolute error ($1000)", color = "Asses on") +
  coord_cartesian(ylim = c(0, NA))
```

---

## Using random forests

```{r show-forest1}
forest1 <- rand_forest(mode = "regression") %>% 
  fit(Sale_Price ~ Latitude + Longitude, ames_train)
show_latlong_model(ames_train, forest1)
```

---

## A random forest has many trees.

```{r}
forest_internals <- extract_fit_engine(forest1)
forest_internals
```

---

## Each tree was trained on a different subset of data

```{r}
ranger::treeInfo(forest_internals, 1) %>% select(-splitvarID) %>% head(10) %>% kable()
```

---

## RF averages the predictions of each tree

```{r}
forest_internals %>% 
  predict(
    data = ames_test %>% head(8),
    predict.all = TRUE, num.trees = 5) %>% 
  pluck("predictions")
```

```{r include=FALSE}
forest_internals %>% 
  predict(
    data = ames_test %>% head(8),
    num.trees = 5) %>% 
  pluck("predictions")
```


---

## Value of Diversity

.scripture[
```
I looked and there before me
was a great multitude that no one could count,
from every nation, tribe, people and language,
standing before the throne.
```

.ref[Revelation 7:9, as quoted in Calvin's "From Every Nation"]
]

- Random Forests work because they combine diverse perspectives (from different training data, different choices)
- Reflects value of diversity in God's Kingdom (see also Rev 5:9, 1 Cor 12, etc.)

---

class: center, middle

# Linear Models

---

## Fitting a linear model

```{r}
linear_model <- linear_reg() %>%
  fit(Sale_Price ~ Gr_Liv_Area, data = ames_train)
linear_model
```

---

## Aside: you may have seen this in stats class.

```{r}
stats::lm(
  formula = Sale_Price ~ Gr_Liv_Area,
  data = ames_train)
```


---

We'll use one example home from the test set.

```{r example-home}
example_home <- ames_test %>% slice(1)
example_home %>% select(Gr_Liv_Area, Sale_Price)
```

---


## What computations can a linear model do?

* *Add* up terms.
* Each term: *multiply* a number by a constant.

.pull-left[
```{r coefs-from-fitted-model}
intercept <- 22.9161
coef_living_area <- 0.1029
```


```{r}
intercept + coef_living_area * 1804
```
]

.pull-right[.small-code[
```{r price-vs-liv-area, out.width="100%"}
ggplot(ames_all, aes(x = Gr_Liv_Area, y = Sale_Price)) +
  geom_point(alpha = .25) +
  geom_hline(yintercept = example_home$Sale_Price, color = "red") +
  geom_vline(xintercept = example_home$Gr_Liv_Area, color = "red") +
  geom_point(data = example_home, color = 'red', size = 5) +
  geom_function(fun = function(x) intercept + coef_living_area * x, color = "blue")
```
]]

---

## Do remodeled homes sell for more?

`Year Remod/Add`: Remodel date *(same as construction date if no remodeling or additions)*
(from dataset documentation)

```{r}
ames_2 <- ames_train %>% mutate(remodeled = Year_Remod_Add != Year_Built)
```


.small-code[
```{r remodeled, out.width = "70%", message=FALSE}
ggplot(ames_2, aes(x = Gr_Liv_Area, y = Sale_Price, color = remodeled)) +
  geom_point(alpha = .25) +
  geom_smooth(method = "lm", se = FALSE)
```
]

---

## Aside: the *sum-as-count* pattern

.pull-left[
```{r}
ames_2 %>%
  group_by(remodeled) %>% 
  summarize(n = n()) %>% 
  mutate(proportion = n / sum(n))
```
]

.pull-right[
```{r}
ames_2 %>% summarize(
  num_remodeled = sum(remodeled),
  prop_remodeled = mean(remodeled)
)
```


Why does this work?


```{r eval=FALSE}
as.numeric(remodeled[1:10])
```

```{r echo=FALSE}
as.numeric(ames_2$remodeled[1:10])
```

<!--
.small[This code needs to run in an environment where `remodeled` is defined, like
a `mutate` or `summarize` of our dataset.]
-->

Its *sum* is the number of 1's (rows where the condition is true). Its *mean* is the sum divided by the total number,
i.e., the *proportion*.

]

---

## Conditional Logic: Simple Conditions

How could a *linear model* treat remodeled homes differently from non-remodeled?

```
if remodeled:
  Sale_Price = intercept_remodeled + coef_sqft * Gr_Liv_Area
else:
  Sale_Price = intercept_other + coef_sqft * Gr_Liv_Area
```

--

### Solution: "**dummy encoding**"

```
Sale_Price = 
   intercept_other 
   + coef_remodeled * (1 if remodeled)
   + coef_sqft      * Gr_Liv_Area
```

---

```{r}
ames_train_2 <- ames_train %>% 
  mutate(remodeled = as_factor(Year_Built != Year_Remod_Add))
  
```


---

.small[

```{r}
ames_recipe_3 <- 
  recipe(Sale_Price ~ Gr_Liv_Area + remodeled, data = ames_train_2) %>% 
  step_dummy(remodeled) %>% #<<
  #step_range(all_numeric(), -all_outcomes(), min = 0, max = 1) %>%
  prep()
baked_ames_train <- 
  ames_recipe_3 %>% bake(new_data = ames_train_2)
baked_ames_train %>% head(5) %>% knitr::kable(format = "html")
```
]

Why are is there no column for `remodeled_FALSE`?

---

## Now, fit as normal.

.small[
```{r message=FALSE}
ames_model_2 <- linear_reg() %>% set_engine("lm") %>% 
  fit(Sale_Price ~ ., data = baked_ames_train)
ames_model_2 %>% tidy() %>% select(term, estimate) %>% kable()
```
]

```{r results="asis", echo=FALSE}
ames_model_2 %>% tidy() %>% pull(estimate, name = term) %>% 
  glue::glue_data("
  \`\`\`
  Sale_Price = 
  {.[['(Intercept)']]} 
     + {.[['Gr_Liv_Area']]} * Gr_Liv_Area
     + {.[['remodeled_TRUE.']]}  * (1 if remodeled)
  \`\`\`", .transformer = function(text, envir) {
    res <- glue::identity_transformer(text, envir)
    format(res, nsmall = 1)
  })
```

or, in "code":

```{r results="asis", echo=FALSE}
ames_model_2 %>% tidy() %>% pull(estimate, name = term) %>% 
  glue::glue_data("
  \`\`\`
  if remodeled:
    Sale_Price = {(Intercept)} + {Gr_Liv_Area} * Gr_Liv_Area - {remodeled_TRUE.} * (1)
    Sale_Price = ({(Intercept)} - {remodeled_TRUE.}) + {Gr_Liv_Area} * Gr_Liv_Area
  else:
    Sale_Price = {(Intercept)} + {Gr_Liv_Area} * Gr_Liv_Area
  \`\`\`", .transformer = function(text, envir) {
    formatC(envir[[text]], format = "f", digits = 1)
  })

```

---

```{r price-vs-liv-area-remodeled, out.width="100%"}
ggplot(baked_ames_train, aes(x = Gr_Liv_Area, y = Sale_Price, color = remodeled_TRUE.)) +
  geom_point() +
  geom_function(fun = function(x) (22.6434248 - 18424.0789) + .1091132 * x, color = "blue") +
  geom_function(fun = function(x) 22.6434248 + .1091132 * x, color = "green")
  
```

---

## More than two options

```
Bldg Type (Nominal): Type of dwelling
       1Fam	Single-family Detached	
       2FmCon	Two-family Conversion; originally built as one-family dwelling
       Duplx	Duplex
       TwnhsE	Townhouse End Unit
       TwnhsI	Townhouse Inside Unit
```

.small-code[
```{r bldg-type, echo = FALSE, out.width="80%"}
ames_all %>% 
  ggplot(aes(x = Gr_Liv_Area, y = Sale_Price, color = Bldg_Type)) +
  geom_point(alpha = .25) +
  geom_smooth(method = "lm")
```
]

---


.small[
```{r}
ames_train %>% count(Bldg_Type) %>% kable()
```

```{r}
ames_recipe_4 <- 
  recipe(Sale_Price ~ Gr_Liv_Area + Bldg_Type, data = ames_train) %>% 
  step_dummy(Bldg_Type) %>% #<<
  prep()
baked_ames_train <- 
  ames_recipe_4 %>% bake(new_data = ames_train_2)
baked_ames_train %>% head(5) %>% knitr::kable(format = "html")
```
]
