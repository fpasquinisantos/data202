<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Modeling: Introduction</title>
    <meta charset="utf-8" />
    <meta name="author" content="DATA 202 21FA" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/font-awesome/css/all.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <link href="libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view/tile-view.js"></script>
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Modeling: Introduction
### DATA 202 21FA

---





## Logistics

- Midterm 1 Online Portion is on Moodle
  - Don't forgot to copy-paste responses and completion code to Moodle
  - Closes Wed evening
- Project Milestone 2 due Friday
- No quiz or Discussion this week

---

## Q&amp;A!

&gt; What kinds of things can functions return?

Anything you can assign to a variable. (numbers, strings, data frames, plots, ...)

&gt; Are `as.numeric` and `as.integer` the same?

&lt;style&gt;.compact-output pre { margin-top: 0; }&lt;/style&gt;

.pull-left[

```r
as.numeric("1.7")
```

```
[1] 1.7
```

```r
as.integer("1.7")
```

```
[1] 1
```
]
.pull-right[

```r
as.integer("One Point Seven")
```

```
Warning: NAs introduced by coercion
```

```
[1] NA
```
]

---



&lt;img src="img/edmunds-estimate.png" width="35%" style="display: block; margin: auto;" /&gt;

What data frame does Edmunds have? Sketch an example. (What are the columns? What does each row represent?)

.floating-source[Edmunds.com]

---

# Missing Data

- Tools so far very good when we have all the data we want.
- Usually we *don't* -- or even we *can't*. 

Different kinds of missingness:

1. How much will this car / house sell for?
2. What will Bitcoin trade for at end-of-day today?
3. What will this addition do to the price of my house?
4. I feel rotten. Is it Covid?
5. What word will the user type next on their keyboard?
6. Will this home-buyer default on their loan?

Discussion:

1. For each of these, discuss **what data is missing** (*why*?).
2. Which of these situations are similar to each other?

---

## Some terminology

- **Supervised learning**: for each item independently, fill in an unobserved variable
  - **Regression**: fill in a *number*
  - **Classification**: fill in a *choice*
- **Unsupervised learning**: identify *relationships* between items
- **Forecasting**: predict how a sequence will continue (future observations)
- **Statistical inference**: fill in summary statistics (we wanted a population but only got a sample)
- **Causal inference**: fill in counterfactuals (what if?)

---

## Predictive Analytics

Mostly *supervised learning* (*regression* and *classification*), some *forecasting*.

* A powerful tool to turn data into action.
* It works because God made the universe predictable (and successful prediction rewarding)
* **Need for wisdom**: It can be used for great good and great harm

---

## Power of Predictive Modeling

* **Medicine**: wearable monitor for seizures or falls, detect malaria from blood smears, find effective drug regimens from medical records
* **Drug Discovery**: predict the efficacy of a synthesis plan for a drug
* **Precision Agriculture**: predict effect of micro-climate on plant growth
* **Urban Planning**: forecast resource needs, extreme weather risks, ...
* **Government**: classify feedback from constituents
* **Retail**: predict items in a grocery order
* **Recommendation systems**: Amazon, Netflix, YouTube, ...
* **User interfaces**: gesture typing, autocomplete / autocorrect

and so much more...

---

## The universe is surprisingly predictable

* God created the world with actionable structure
  * We gradually learn how to perceive that structure and act within it.
  * The better our perceptions align with how the universe is structured, the better our actions
  * We can discover that structure by learning to be less surprised by what we see ( = predicting our perceptions)
* Perceptions are thus both accurate and fallable.

---

## Predictive modeling technology: Need for wisdom

* Potential for great good
* But also great harm:
  * Lack of **fairness** in facial recognition, sentencing, lending, job applicant scoring, ...
  * Lack of **transparency** in how "Big Data" systems make conclusions
  * Lack of **privacy** as data is increasingly collected and aggregated
  * Amplification of extreme positions in social media, YouTube, etc.
  * Oversimplification of human experience
  * Hidden human labor
  * Illusion of objectivity
  * ...!

---

class: center, middle

# Wednesday

---

## Q&amp;A

&gt; How will we code predictive models?

- We'll use `tidymodels`, a toolkit like `tidyverse`. Preview today, practice Friday.
- We'll need all our `tidyverse` skills to understand our data before modeling it and to visualize our models.

&gt; What are the limits? Can we predict everything?

- Silicon Valley: "Yes!"
- Wisdom: "No!"
  - [What failure to predict life outcomes can teach us](https://www.pnas.org/content/117/15/8234)
  - Predictions can be inaccurate and biased, with disparate impacts on vulnerable people.


---

## Different kinds of missing data

- Missing *items*: entire rows not in your data.
  - Some people didn't fill out your survey.
  - You only know about people who *did* visit your website, not those that didn't. etc.
- Missing *observations*: row present, but some observations missing
  - someone added a product to their cart but didn't buy it, so you don't know their address.
  - only some people got an expensive diagnostic test. etc.

---

## Why not just ignore what's missing?

- Ignoring missing data leads to [selection bias](https://catalogofbias.org/biases/selection-bias/) and related biases (see catalogofbias.org).
- Missing *observations* can be exactly the info you need for making a decision, e.g., what price to list your product for.
- Implications:
  - **Never** `drop_na()` without explanation.
  - "The map is not the territory" -- data â‰  objective reality

---

class: center, middle

# Examples of Supervised Learning

---

## Regression Example: Home Sales



From Ames, Iowa home sales, 2006-2010. (De Cock, 2011)

.small[
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; Lot_Area &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Bldg_Type &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Gr_Liv_Area &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Garage_Cars &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Sale_Price &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 12546 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; OneFam &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1440 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;color: white !important;background-color: #8C2131 !important;"&gt; 182.9 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 2645 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Twnhs &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1586 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;color: white !important;background-color: #8C2131 !important;"&gt; 170.0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 15312 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; OneFam &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1138 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;color: white !important;background-color: #8C2131 !important;"&gt; 148.0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 8544 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Duplex &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1040 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;color: white !important;background-color: #8C2131 !important;"&gt; 81.4 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 12677 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TwnhsE &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1518 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:right;color: white !important;background-color: #8C2131 !important;"&gt; 274.0 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]
(2412 total rows)

* *y*: *response* variable (aka *outcome*, *dependent variable*): `Sale_Price`
* *X*: *features* (aka *predictors*, *covariates*, etc.): everything else

Note: `X` is much easier to measure than `y`

---





.panelset[
.panel[.panel-name[Model]
&lt;img src="w07d1-modeling-intro_files/figure-html/gr_liv_stub-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.panel[.panel-name[Predictions]
&lt;img src="w07d1-modeling-intro_files/figure-html/decision-tree-example-fit-1.png" width="100%" style="display: block; margin: auto;" /&gt;

]
.panel[.panel-name[Model code]


```r
library(tidymodels)
set.seed(10) # Make consistent train-test splits.
ames_split &lt;- initial_split(ames_home_sales, prop = 2/3) # Split our data randomly
ames_train &lt;- training(ames_split)
ames_test &lt;- testing(ames_split)
```


```r
*decision_tree_fit &lt;- decision_tree(mode = "regression", tree_depth = 3) %&gt;%
  set_engine("rpart") %&gt;% 
  fit(
    Sale_Price ~ Gr_Liv_Area + Bldg_Type,
    data = ames_train)
```


Plotting the tree:


```r
decision_tree_fit %&gt;% 
  extract_fit_engine() %&gt;% 
  rpart.plot::rpart.plot(roundint = FALSE)
```

]
]

---

## Were those predictions good?


```r
metrics &lt;- yardstick::metric_set(mae, mape, rsq_trad, rmse)
decision_tree_fit %&gt;% 
  predict(ames_test) %&gt;% 
  bind_cols(ames_test) %&gt;% 
  metrics(truth = Sale_Price, estimate = .pred) %&gt;% 
  select(-.estimator) %&gt;% knitr::kable()
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; .metric &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; .estimate &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; mae &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35.3756288 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; mape &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 21.1170598 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; rsq_trad &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.5254953 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; rmse &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 50.5840333 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

- Traditional R^2 (fraction of variance explained)
- MAE: Mean Absolute Error ("predictions are usually off by $xxx")
- MAPE: Mean Absolute Percent Error ("predictions are usually off by yy%")
- RMSE: Root Mean Squared Error: mathy, but sorta like the standard deviation

---

## Classification example: Can a blood test diagnose autism?

We'll use an example from a [2017 PLOS Computational Biology paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005385)







```r
autism
```

```
# A tibble: 206 Ã— 26
  Group Methion.   SAM   SAH `SAM/SAH` `% DNA methylatioâ€¦ `8-OHG`
  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;              &lt;dbl&gt;   &lt;dbl&gt;
1 ASD       17.3  56.2 15.2       3.69               3.35   0.055
2 ASD       14.9  37.2  7.58      4.91               3.04   0.045
3 ASD       15.9  37.9  9.87      3.84               2.81   0.058
4 ASD       18.7  79.2 24.5       3.23               4.24   0.085
5 ASD       21.5  77.6 19.2       4.04               3.49   0.041
6 ASD       18.1  67.6 12.8       5.30               3.01   0.156
# â€¦ with 200 more rows, and 19 more variables: Adenosine &lt;dbl&gt;,
#   Homocysteine &lt;dbl&gt;, Cysteine &lt;dbl&gt;, Glu.-Cys. &lt;dbl&gt;,
#   Cys.-Gly. &lt;dbl&gt;, tGSH &lt;dbl&gt;, fGSH &lt;dbl&gt;, GSSG &lt;dbl&gt;,
#   fGSH/GSSG &lt;dbl&gt;, tGSH/GSSG &lt;dbl&gt;, Chlorotyrosine &lt;dbl&gt;,
#   Nitrotyrosine &lt;dbl&gt;, Tyrosine &lt;dbl&gt;, Tryptophane &lt;dbl&gt;,
#   fCystine &lt;dbl&gt;, fCysteine &lt;dbl&gt;, fCystine/fCysteine &lt;dbl&gt;,
#   % oxidized &lt;dbl&gt;, Vineland ABC &lt;dbl&gt;
```


---

We have 3 kinds of data about 206 children:

1. The outcome (`Group`): ASD (diagnosed with ASD), SIB (sibling not diagnosed with ASD), and NEU (age-matched neurotypical children, for control)


```r
autism %&gt;% group_by(Group) %&gt;% summarize(n = n()) %&gt;% knitr::kable()
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Group &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; n &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; ASD &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 83 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; NEU &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 76 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; SIB &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 47 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

1. The outcome (`Group`): ASD, SIB, NEU
2. Concentrations of various metabolites in a blood sample:


```r
autism %&gt;% select(-1, -last_col())
```

```
# A tibble: 206 Ã— 24
  Methion.   SAM   SAH `SAM/SAH` `% DNA methylation` `8-OHG`
     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;               &lt;dbl&gt;   &lt;dbl&gt;
1     17.3  56.2 15.2       3.69                3.35   0.055
2     14.9  37.2  7.58      4.91                3.04   0.045
3     15.9  37.9  9.87      3.84                2.81   0.058
4     18.7  79.2 24.5       3.23                4.24   0.085
5     21.5  77.6 19.2       4.04                3.49   0.041
6     18.1  67.6 12.8       5.30                3.01   0.156
# â€¦ with 200 more rows, and 18 more variables: Adenosine &lt;dbl&gt;,
#   Homocysteine &lt;dbl&gt;, Cysteine &lt;dbl&gt;, Glu.-Cys. &lt;dbl&gt;,
#   Cys.-Gly. &lt;dbl&gt;, tGSH &lt;dbl&gt;, fGSH &lt;dbl&gt;, GSSG &lt;dbl&gt;,
#   fGSH/GSSG &lt;dbl&gt;, tGSH/GSSG &lt;dbl&gt;, Chlorotyrosine &lt;dbl&gt;,
#   Nitrotyrosine &lt;dbl&gt;, Tyrosine &lt;dbl&gt;, Tryptophane &lt;dbl&gt;,
#   fCystine &lt;dbl&gt;, fCysteine &lt;dbl&gt;, fCystine/fCysteine &lt;dbl&gt;,
#   % oxidized &lt;dbl&gt;
```

---

1. The outcome (`Group`): ASD, SIB, NEU
2. Concentrations of various metabolites in a blood sample
3. For the ASD children only, a measure of life skills ("Vineland ABC")


```r
autism %&gt;% 
  ggplot(aes(x = `Vineland ABC`, y = Group)) + geom_boxplot()
```

```
Warning: Removed 159 rows containing non-finite values
(stat_boxplot).
```

&lt;img src="w07d1-modeling-intro_files/figure-html/show-behavior-score-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

## Exploratory Data Analysis (EDA)

What do these metabolites look like?

&lt;img src="w07d1-modeling-intro_files/figure-html/bad-metabolite-plot-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

code for the previous plot:

```r
library(ggridges)
autism %&gt;%
  select(-`Vineland ABC`) %&gt;% 
  pivot_longer(-Group, names_to = "Measure") %&gt;% 
  ggplot(aes(x = value, y = Measure)) +
  geom_density_ridges() + 
  facet_wrap(vars(Group), scales = "free_x")
```

---

## EDA

Better question: **Can these metabolites help us distinguish autism?**

---

&lt;img src="w07d1-modeling-intro_files/figure-html/ridgeplot-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

code for previous plot:


```r
autism %&gt;%
  select(-`Vineland ABC`) %&gt;% 
  pivot_longer(-Group, names_to = "Measure") %&gt;% 
  ggplot(aes(x = value, y = Group)) +
  geom_density_ridges() +
  facet_wrap(vars(Measure), scales = "free_x") + 
  theme_ridges()
```

---

## Can we predict ASD vs non-ASD from metabolites?

* Let's start by (1) ignoring the behavior scores (that's an *outcome*) and comparing
just ASD and NEU.
* We need to drop SIB and encode `Group` as a factor.


```r
data &lt;- autism %&gt;% 
  select(-`Vineland ABC`) %&gt;% 
  filter(Group != "SIB") %&gt;% 
  mutate(Group = as_factor(Group))
```

---

## Decision Tree *Classification*


```r
spec &lt;- workflow() %&gt;% add_recipe(
* recipe(Group ~ ., data = data)) %&gt;%
* add_model(decision_tree(mode = "classification") %&gt;% set_engine("rpart"))
model &lt;- spec %&gt;% fit(data)
```


&lt;img src="w07d1-modeling-intro_files/figure-html/show-tree-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

### What do the *predictions* look like?


```r
model %&gt;% predict(data, type = "prob")
```

```
# A tibble: 159 Ã— 2
  .pred_ASD .pred_NEU
      &lt;dbl&gt;     &lt;dbl&gt;
1     0.959    0.0411
2     0.959    0.0411
3     0.959    0.0411
4     0.959    0.0411
5     0.959    0.0411
6     0.959    0.0411
# â€¦ with 153 more rows
```

---

### Were those predictions *good*?

.small-code[

```r
model %&gt;%
  predict(data, type = "prob") %&gt;%
  bind_cols(data) %&gt;% 
  mutate(idx = row_number()) %&gt;% 
  ggplot(aes(x = idx, y = .pred_ASD, color = Group, shape = Group)) +
  geom_hline(yintercept = .5) +
  geom_point() 
```

&lt;img src="w07d1-modeling-intro_files/figure-html/plot-predicted-probs-tree-1.png" width="90%" style="display: block; margin: auto;" /&gt;
]

---

### Quantifying that:


```r
metrics &lt;- yardstick::metric_set(accuracy, sensitivity, specificity)
model %&gt;% 
  predict(data, type = "class") %&gt;% 
  bind_cols(data) %&gt;% 
  metrics(truth = Group, estimate = .pred_class)
```

```
# A tibble: 3 Ã— 3
  .metric  .estimator .estimate
  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
1 accuracy binary         0.912
2 sens     binary         0.928
3 spec     binary         0.895
```

---

## Classification Metrics

|                      | Event happened              | No event happened           |
|----------------------|-------------------------------|-------------------------------|
| Event predicted    | True positive                 | False positive (Type 1 error) |
| No event predicted | False negative (Type 2 error) | True negative                 |

--

- **Accuracy** (% correct) = (TP + TN) / (# episodes)
- **False negative** ("miss") **rate** = FN / (# actual events)
- **False positive** ("false alarm") **rate** = FP / (# true non-events)

--

- **Sensitivity** ("true positive rate") = TP / (# actual events)
  - Sensitivity = 1 âˆ’ False negative rate
- **Specificity** ("true negative rate") = TN / (# actual events)
  - Specificity = 1 âˆ’ False positive rate
- [Wikipedia article](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "4:3",
"highlightLines": true,
"highlightStyle": "solarized-light",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
