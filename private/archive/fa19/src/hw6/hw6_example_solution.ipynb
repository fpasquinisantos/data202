{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 202 Homework 6: Data Wrangling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capital Bikeshare Rides Data\n",
    "\n",
    "Download the [2011 trip data](https://s3.amazonaws.com/capitalbikeshare-data/2011-capitalbikeshare-tripdata.zip) from [Capital Bikeshare](https://www.capitalbikeshare.com/system-data). Don't need to unzip the ZIP file; Pandas will handle it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides = pd.read_csv(\"2011-capitalbikeshare-tripdata.zip\")\n",
    "rides.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:,d}'.format(len(rides)))\n",
    "rides.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove some columns we don't need, to save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del rides[\"Start station\"], rides[\"End station\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code gets us a table of federal holidays. Please run it without changing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code unchanged.\n",
    "holidays = pd.DataFrame({\n",
    "    'date': USFederalHolidayCalendar().holidays(datetime.date(2011,1,1), datetime.date(2015,12,31)).date,\n",
    "    'is_holiday': True})\n",
    "holidays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data\n",
    "Our main goal will be to get the hourly temperature data.\n",
    "\n",
    "The original wranglers used a weather data source that does not seem to provide downloadable data anymore. But we can use the US government's records. They're in a cumbersome format, which will provide us an excuse to practice some **data cleaning**!\n",
    "\n",
    "First challenge is where to find the data. Here's how we solved this hard problem:\n",
    "\n",
    "NOAA's [Integrated Surface Database](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets) provides weather data from all over the country. But how to use it? There's a \"Find a Station\" tool, but it's confusing how to use the results. https://www.ncdc.noaa.gov/data-access/land-based-station-data/station-metadata has a link to a [station list file](ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-history.txt). Searching that, it looks like the code for Reagan Airport is 724050 13743. So the file is\n",
    "https://www.ncei.noaa.gov/data/global-hourly/access/2011/72405013743.csv\n",
    "\n",
    "Poking around in that site revealed two documents that look very important:\n",
    "- https://www.ncei.noaa.gov/data/global-hourly/doc/isd-format-document.pdf\n",
    "- https://www.ncei.noaa.gov/data/global-hourly/doc/CSV_HELP.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to load the file directly from the NOAA website.\n",
    "# You may want to make a local copy and read it in from there instead.\n",
    "weather = pd.read_csv(\"https://www.ncei.noaa.gov/data/global-hourly/access/2011/72405013743.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(weather))\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe of only needed columns\n",
    "weather1 = pd.to_datetime(weather['DATE']).to_frame()\n",
    "weather1[\"DATE\"].iloc[0]\n",
    "\n",
    "#Split up date and hour for the eventual merge\n",
    "weather1[\"Date\"] = weather1['DATE'].dt.date\n",
    "weather1[\"Date\"] = pd.to_datetime(weather1[\"Date\"])\n",
    "weather1[\"Hour\"] = weather1['DATE'].dt.hour\n",
    "\n",
    "#Edit the temerature string so it's in the correct format\n",
    "weather1[\"temp_C\"] = weather[\"TMP\"].str.replace(\"+\", \"\")\n",
    "weather1[\"temp_C\"] = weather1[\"temp_C\"].str.replace(\",\", \".\")\n",
    "#Handles a unique and odd entry that is inccorect\n",
    "weather1[\"temp_C\"] = weather1[\"temp_C\"].str.replace(\".A\", \"\")\n",
    "weather1[\"temp_C\"] = weather1[\"temp_C\"].astype(float) / 10\n",
    "\n",
    "weather1 = weather1.groupby([\"Date\", \"Hour\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract `date` and `hour`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides['start'] = pd.to_datetime(rides['Start date'])\n",
    "rides['start'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rides['date'] = rides['start'].dt.date#strftime(\"%Y-%m-%d\")\n",
    "rides['hour'] = rides['start'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filter to include only rides by Members\n",
    "You'll end up with a Series with a hierarchical index; remember that the \"get out of jail card\" is `.to_frame(name=\"NAME_GOES_HERE\").reset_index()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "rides = rides[rides[\"Member type\"] == \"Member\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Combine all rows for a single hour of the same day into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine days and hours together, and show amount of rides per hour of each day.\n",
    "rides = rides.groupby(['date', 'hour']).size().to_frame(\"rides\").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Add \"is_holiday\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides = pd.merge(rides, holidays, left_on=\"date\", right_on=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in the days that were missing\n",
    "rides[\"is_holiday\"] = rides[\"is_holiday\"].fillna(\"False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Add day of week column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides['date'] = pd.to_datetime(rides['date'])\n",
    "rides['day_of_week'] = rides['date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Add is_weekend and is_workingday column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saturday and Sunday are days 5 and 6\n",
    "rides[\"is_weekend\"] = rides[\"day_of_week\"] >= 5\n",
    "rides[\"is_workingday\"] = rides[\"day_of_week\"] < 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Add temperature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(rides, weather1, left_on=(\"date\", \"hour\"), right_on=(\"Date\", \"Hour\"), how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yay, we're done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(merged_data) > 365 * 23\n",
    "assert 'date' in merged_data.columns\n",
    "assert 'hour' in merged_data.columns\n",
    "assert 'is_holiday' in merged_data.columns\n",
    "assert 'temp_C' in merged_data.columns\n",
    "assert 'rides' in merged_data.columns\n",
    "assert len(merged_data.dropna()) == len(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(\"https://gbfs.capitalbikeshare.com/gbfs/en/station_information.json\")\n",
    "resp_json = resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.DataFrame(resp_json['data']['stations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations.query('short_name == \"31620\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.Map(\n",
    "    location=[42.961111, -85.655556],\n",
    "    zoom_start=13\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(\n",
    "    location=[38.9, -77.],\n",
    "#    tiles='Stamen Toner',\n",
    ")\n",
    "\n",
    "for station in stations.itertuples():\n",
    "    folium.Marker(location=[station.lat, station.lon], tooltip=station.name).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.Map(\n",
    "    location=[42.961111, -85.655556],\n",
    "    tiles='Stamen Toner',\n",
    "    zoom_start=13\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
