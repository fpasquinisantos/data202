# Recommender Systems and Reinforcement Learning: Data Science that Acts

## Attention Engineering

* Skim [this article](https://www.theverge.com/2019/7/30/20746878/josh-hawley-dark-patterns-platform-design-autoplay-youtube-videos-scrolling-snapstreaks-illegal) proposing that some recommender system functions be illegal. (Alternative coverage, if you're interested, on [the Federalist](https://thefederalist.com/2019/08/13/hawleys-smart-act-beginning-revolt-big-tech/))
* Read `rsweeny21`'s [comment](https://news.ycombinator.com/item?id=20566514) about this article on Hacker News.
* Do you agree with [this author's analogy of Netflix as the "forbidden woman"](https://www.thegospelcoalition.org/article/quit-netflix/) of Proverbs?

## What content gets recommended?

* Skim [this opinion piece on Wired](https://www.wired.com/story/creating-ethical-recommendation-engines/). Pick one of the other articles she links to and skim it.
* Lest you think it's easy to identify and remove radicalizing content, [think again](https://reason.com/2018/07/03/facebook-algorithm-flags-removes-declara/).

## Technical Approaches

* Do you use Pinterest? [Here's how it works](https://blog.acolyer.org/2018/05/23/pixie-a-system-for-recommending-3-billion-items-to-200-million-users-in-real-time/).
* [YouTube's Recommender System](https://blog.acolyer.org/2016/09/19/deep-neural-networks-for-youtube-recommendations/)

Both of these papers are from a blog called The Morning Paper. If you can only read one CS blog, this one would be my recommendation.

## Other 

* [Auditing Radicalization Pathways on YouTube](https://arxiv.org/pdf/1908.08313.pdf)