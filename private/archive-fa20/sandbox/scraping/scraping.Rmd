---
title: "Scraping"
author: "K Arnold"
date: "11/15/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rvest)
```

## Wunderground

<https://www.wunderground.com/history/monthly/KGRR/date/2020-11>

```{r}
data <- jsonlite::fromJSON("wunderground-hist.json")
data$observations %>% glimpse()
```


## Solar flare

Caleb: <https://archive.ics.uci.edu/ml/datasets/Solar+Flare>

```{r}
read_delim("flare.data1", delim = " ", skip = 1, col_names = FALSE, col_types = "cccdddddddddd")
```

## Weather Data

Our main goal will be to get the hourly temperature data.

First challenge is where to find the data. Here's how we solved this hard problem:

NOAA's [Integrated Surface Database](https://www.ncdc.noaa.gov/data-access/land-based-station-data/land-based-datasets) provides weather data from all over the country. But how to use it? There's a "Find a Station" tool, but it's confusing how to use the results. https://www.ncdc.noaa.gov/data-access/land-based-station-data/station-metadata has a link to a [station list file](ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-history.txt). Searching that, it looks like the code for Reagan Airport is 724050 13743. So the file is
https://www.ncei.noaa.gov/data/global-hourly/access/2011/72405013743.csv

Grand Rapids is `GHCND:USC00206013`
or `999999 14830` (what's the relationship of that to the above?)


https://www.ncei.noaa.gov/data/global-hourly/access/2020/01483099999.csv --- no, the latlong is wrong

Poking around in that site revealed two documents that look very important:
- https://www.ncei.noaa.gov/data/global-hourly/doc/isd-format-document.pdf
- https://www.ncei.noaa.gov/data/global-hourly/doc/CSV_HELP.pdf

```{r}
# This one seems wrong.
#download.file("https://www.ncei.noaa.gov/data/global-hourly/access/2020/01483099999.csv", "01483099999.csv")
```

I made a (free) data order for 2020 for GRR at <https://www.ncdc.noaa.gov/cdo-web/datatools/lcd>.

```{r}
grr_2020 <- read_csv("2354955.csv", guess_max = 1e6)
```


From that I see the actual station ID is 72635094860.
So the direct download file would be <https://www.ncei.noaa.gov/data/global-hourly/access/2020/72635094860.csv>

```{r}
download.file("https://www.ncei.noaa.gov/data/global-hourly/access/2020/72635094860.csv", "72635094860.csv")

```


```{r}
grr_2020_2 <- read_csv("72635094860.csv", guess_max = 1e6)
```


## BigQuery

<https://console.cloud.google.com/marketplace/product/bigquery-public-datasets/covid19-open-data?filter=solution-type:dataset&q=covid19&project=calvindsdev>

```
WITH
  country_pop AS (
  SELECT
    country_code AS iso_3166_1_alpha_3,
    year_2018 AS population_2018
  FROM
    `bigquery-public-data.world_bank_global_population.population_by_country`)
SELECT
  country_code,
  country_name,
  cumulative_confirmed AS june_confirmed_cases,
  population_2018,
  ROUND(cumulative_confirmed/population_2018 * 100,2) AS case_percent
FROM
  `bigquery-public-data.covid19_open_data.covid19_open_data`
JOIN
  country_pop
USING
  (iso_3166_1_alpha_3)
WHERE
  date = '2020-11-13'
  AND aggregation_level = 0
  AND population_2018 > 100000000
ORDER BY
  case_percent DESC
```

See also: <https://www.reddit.com/r/bigquery/comments/3cej2b/17_billion_reddit_comments_loaded_on_bigquery/>
from <https://fivethirtyeight.com/features/dissecting-trumps-most-rabid-online-following/>
