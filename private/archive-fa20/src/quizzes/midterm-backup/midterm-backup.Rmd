---
title: "Midterm (backup version)"
output: html_document
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = file.path(dirname(inputFile), 'midterm-ref.html')) })
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(dplyr)
library(tidyr)
library(readr)
library(stringr)
library(forcats)
library(ggplot2)
library(parsnip)
library(rsample)
# Disable a warning message.
options(dplyr.summarise.inform = FALSE)

theme_set(theme_light())

car_prices <- readxl::read_excel("data/kuiper.xlsx") %>% janitor::clean_names()
fuel_eco <- read_csv("data/guide2005-2004oct15.csv") %>% janitor::clean_names()

fuel_eco_avg <- 
  fuel_eco %>% 
  group_by(manufacturer, carline_name) %>% 
  summarize(
    city = mean(cty),
    highway = mean(hwy),
    combined = mean(cmb)
  )

car_prices_and_eco <- 
  car_prices %>% 
  mutate(carline_name = str_to_upper(model)) %>% 
  left_join(
    fuel_eco_avg,
    by = "carline_name")

set.seed(0)
cars_split <- initial_split(car_prices, prop = 3/4, strata = "make")
cars_train <- training(cars_split)
cars_test <- testing(cars_split)
```

## Visualization

This quiz uses a dataset from [Kuiper 2017](https://www.tandfonline.com/doi/full/10.1080/10691898.2008.11889579)
of car sale prices from Kelly Blue Book for several hundred 2005 used General Motors (GM) cars.
The [link to the data set](http://ww2.amstat.org/publications/jse/v16n3/kuiper.xls) can be found at the bottom of the article,
if you're interested in running this analysis on your own computer.

```{r load-data, eval=TRUE}
car_prices <- readxl::read_excel("data/kuiper.xlsx") %>% 
  janitor::clean_names()
```

(The [`janitor`](http://sfirke.github.io/janitor/) package provides some convenient
[utilities](http://sfirke.github.io/janitor/articles/janitor.html) for cleaning data.
Here we used `clean_names` to make sane formatting for all of the names.)

Let's take a quick look at the data:

```{r show-data, echo=TRUE}
car_prices %>% head()
car_prices %>% glimpse()
```

### Reproduce a plot

#### Price by Mileage

**Write code to reproduce the following visualization**, intended to show that
lower-mileage cars tend to be valued more highly.

Tips:

* See the [Visualization Tweaks](https://cs.calvin.edu/courses/data/202/fa20/notes/visualization.html#tweaks)
  section of the course notes for tips on the scales.

```{r mileage-plot, echo=FALSE}
car_prices %>% 
  ggplot(aes(x = mileage, y = price / 1000, color = type, shape = type)) +
  geom_point() +
  scale_x_continuous(labels = scales::comma) +
  labs(x = "Mileage (mi)", y = "Price ($1000)")
```


**Extra credit (save this for last!)**: can you figure out how to make this plot? It shows the same data in 
each pane, but highlights the cars of each given type. 

Tip: two `geom_point` layers, one with `data` set to `car_prices` *without the `type` column*.

```{r mileage-plot-improved, echo=FALSE}
car_prices %>%
  ggplot(aes(x = mileage / 1000, y = price / 1000, color = make, shape = make)) +
  geom_point(data = car_prices %>% select(-"type"), color = "grey", size = .5) + 
  geom_point(size = 1) +
  facet_wrap(vars(type)) + 
  labs(x = "Mileage (1000 mi)", y = "Price ($1000)")
```

### High or Low Mileage

**Write code to reproduce the following visualization**, intended to show whether
mileage affects price differently for different types of cars.
Consider a car to be "low mileage" if its mileage is less than the median
mileage.

Details:

* The types should be in order of median `price`. (`fct_reorder`)
* The x axis should include 0. (`xlim`)


```{r mileage-lo-hi, echo=FALSE}
car_prices %>% 
  #group_by(type) %>% 
  mutate(low_mileage = mileage < median(mileage)) %>% 
  ggplot(aes(y = fct_reorder(type, price), x = price / 1000, color = low_mileage)) +
    geom_boxplot() +
    labs(y = "", x = "Price ($1000)", color = "Low mileage") +
    xlim(c(0, NA))
```

## Data Wrangling

**What was the most common car `make` in this data set?**



**Make a table** showing, for each car `type`, what proportion of the listed cars had
cruise control. Note that the `cruise` column contains a 1 if the listed car
has cruise control, 0 if it doesn't, so you can use math functions here. Your table should have 5 rows.
**Sort the table from highest to lowest fraction**.

Which car type **least frequently** had cruise control?

Do 2-door cars or 4-door (`doors`) cars have bigger engines (`liter` column) on average in this data set?

## Align, Combine, and Reshape

For increasingly many consumers, fuel economy is a deciding factor in purchasing
decisions. However, the Kelly Blue Book data set doesn't include any fuel economy
data. Fortunately the US Department of Energy and the EPA put together
<https://www.fueleconomy.org>. That site provides both consumer-facing tools
to compare the monetary and environmental fuel costs of various vehicles.
Fortunately they also release machine-readable [data files](https://www.fueleconomy.gov/feg/download.shtml).
According to the Kuiper 2017 article, all of the vehicles were 2005 model year
and less than a year old, so the 2005 data has been downloaded for you:

```{r load-mpg, echo=TRUE, message=FALSE}
fuel_eco <- read_csv("data/guide2005-2004oct15.csv") %>% janitor::clean_names()
```

Notable columns are (descriptions are quoted from the EPA's [guide](https://www.fueleconomy.gov/feg/pdfs/guides/FEG2005.pdf)):

* `manufacturer` and `carline_name`: the make and model of the car tested.
* `cty`: *City* represents urban driving, in which a vehicle is started in the morning (after being parked all night) and driven in stop-and-go rush hour traffic
* `hwy`: *Highway* represents a mixture of rural and interstate highway driving in warmed-up vehicles, typical of longer trips in free-flowing traffic.
* `cmb`: *Combined* city and highway MPG estimates ... assume you will drive 55% in the city and 45% on the highway.

(Full documentation from the source is available [here](https://www.fueleconomy.gov/feg/epadata/Readme.txt)
but is not needed for these exercises.)

We first briefly verify that the *carline name* is sufficiently unique to describe a car; there
are no cars with the same name but different manufacturers:

```{r verify-distinct, echo=TRUE}
fuel_eco %>% distinct(carline_name) %>% nrow()
fuel_eco %>% distinct(manufacturer, carline_name) %>% nrow()
```

Good to go. But a brief look at the dataset immediately reveals two potential problems:

```{r show-fuel-eco-caps, echo=TRUE}
fuel_eco %>% select(manufacturer, carline_name, cty, hwy, cmb) %>% head(5)
```

*First problem*: *each car may be reported several times* in the EPA dataset, once
for each different engine option or transmission type. We could work out
some of that data from the `trim` column, but for a first pass, let's just
take the *average* mileages for a given `carline_name`.

**Make a table called `fuel_eco_avg`** that gives the average `cty`, `hwy`, and `cmb`
fuel economy for each `manufacturer` and `carline_name`. While you're at it, use more sensible names:
`city`, `highway`, and `combined`. The result should look like:

```{r show-fuel-eco-avg, eval=TRUE}
fuel_eco_avg
```

*Second problem*: the EPA uses all-caps for car names but the Kelly Blue Book didn't.
So none of the EPA's `carline_name`s in `fuel_eco` will match the `model`s in `car_prices`.
Let's look at `car_prices` again for reference:

```{r show-car-prices-head, echo=TRUE}
car_prices %>% distinct(make, model) %>% head(5)
```

But we won't let that stop us! Here's a strategy: ignore case. Specifically:

**Make a table called `car_prices_and_eco`** that has the city, highway, and
combined fuel economy for all of the cars in `car_prices`.
To ignore case in the matching, *upper-case* (`str_to_upper()`) the models in
`car_prices` and  put the result in a *new column*, which you can then use to
look up fuel economies in `fuel_eco_avg`. For cars that don't match the EPA
data even after
ignoring case, leave the fuel economies at `NA` (don't drop the row).

Tip: how many rows should the result have?

**How many distinct car models didn't match the EPA data?**

**Reproduce the following graph** using the `car_prices_and_eco` dataset.

```{r price-by-eco}
car_prices_and_eco %>% 
  pivot_longer(c(city, highway, combined), names_to = "measure", values_to = "economy") %>% 
  drop_na(economy) %>% 
  ggplot(aes(x = economy, y = price / 1000, color = fct_relevel(measure, "city", "highway", "combined"))) +
  geom_point() +
  geom_smooth() +
  labs(x = "Fuel Economy", y = "Price ($1000)", color = "Measure")
```

*Note*: I used `fct_relevel` to adjust the order of the measures, but you may 
leave it at the default order for full credit.

## Modeling

Let's try to make some models to predict `price`.

We'll hold out a testing set so we can validate our model.

```{r train-test-split, echo=TRUE}
set.seed(0)
cars_split <- initial_split(car_prices, prop = 3/4, strata = "make")
cars_train <- training(cars_split)
cars_test <- testing(cars_split)
```


First, create a `tidymodels` model called `model` that predicts `price` from `mileage` 
using linear regression on the training set. (You do not need a recipe here.)

Then, write code to recreate the following plot, which shows how the 
*residuals* (actual minus predicted) depend on the car type.
Plots like this can be useful for showing whether it's helpful to add additional
features to the predictive model.

```{r residual-by-type-plot, eval=TRUE}
model <- 
  parsnip::linear_reg() %>% 
  set_engine('lm') %>% 
  fit(price ~ mileage, data = cars_train)

model %>% 
  predict(cars_train) %>% 
  bind_cols(cars_train) %>% 
  mutate(residual = price - .pred) %>% 
  ggplot(aes(y = fct_reorder(type, residual), x = residual)) +
    geom_vline(xintercept = 0) +
    geom_boxplot() +
    labs(y = "")
```

*Note*: We're stopping short of a full predictive modeling workflow to keep this midterm
at a manageable length.
