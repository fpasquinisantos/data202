---
title: "Test"
author: "Kenneth C. Arnold"
date: "7/31/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Core stuff
library(tidyverse)
library(tidymodels)
library(ggformula)
library(plotly)
library(reticulate)

# Other
library(devtools)
library(usethis)
library(keras)
library(forcats)
library(rvest)
library(nycflights13)
library(skimr)
library(pins)
library(timeDate)
library(qualtRics)
```


# A simple tidymodels example

From their tutorial


```{r}
urchins <-
  # Data were assembled for a tutorial 
  # at https://www.flutterbys.com.au/stats/tut/tut7.5a.html
  pin("https://tidymodels.org/start/models/urchins.csv") %>% 
  read_csv() %>% 
  # Change the names to be a little more verbose
  setNames(c("food_regime", "initial_volume", "width")) %>% 
  # Factors are very helpful for modeling, so we convert one column
  mutate(food_regime = factor(food_regime, levels = c("Initial", "Low", "High")))
```

Visualize using `ggformula`

```{r}
urchins %>% 
  gf_point(width ~ initial_volume, color = ~ food_regime) %>% 
  gf_smooth(method=lm)
```
Visualize using plotly

```{r}
urchins %>% 
  gf_point(width ~ initial_volume, color = ~ food_regime) %>% 
  gf_smooth(method=lm) %>% 
  ggplotly()
```
Low-level interface

```{r}
plot_ly(urchins) %>% 
  add_markers(
    x = ~ initial_volume,
    y = ~width,
    color = ~ food_regime
  )
```

## Fit tidy model

```{r}
lm_mod <- 
  linear_reg() %>% 
  set_engine("lm")
lm_mod
```

```{r}
lm_fit <- 
  lm_mod %>% 
  fit(width ~ initial_volume * food_regime, data = urchins)
lm_fit %>% tidy()
```

```{r}
new_points <- expand_grid(
  initial_volume = 20,
  food_regime = urchins %>% pull(food_regime) %>% fct_unique()
)
new_points
```

```{r}
bind_cols(
  new_points,
  lm_fit %>% predict(new_data = new_points),
  lm_fit %>% predict(new_data = new_points, type = "conf_int")
) %>% 
  gf_point(.pred ~ food_regime) %>% 
  gf_errorbar(.pred_lower + .pred_upper ~ food_regime, width = .2)
```

# Flight data example (also from tidymodels)

```{r}
set.seed(123)

flight_data <- 
  flights %>% 
  mutate(
    # Convert the arrival delay to a factor
    arr_delay = ifelse(arr_delay >= 30, "late", "on_time") %>% as_factor(),
    # We will use the date (not date-time) in the recipe below
    date = as.Date(time_hour)
  ) %>% 
  # Include the weather data
  inner_join(weather, by = c("origin", "time_hour")) %>% 
  # Only retain the specific columns we will use
  select(dep_time, flight, origin, dest, air_time, distance, 
         carrier, date, arr_delay, time_hour) %>% 
  # Exclude missing data
  na.omit() %>% 
  # For creating models, it is better to have qualitative columns
  # encoded as factors (instead of character strings)
  mutate_if(is.character, as.factor) %>% 
  
  # Keep a small subset so this runs quickly.
  slice_sample(n = 10000)
```


```{r}
flight_data %>% 
  count(arr_delay) %>% 
  mutate(prob = n / sum(n))
```

```{r}
set.seed(555)

data_split <- initial_split(flight_data, prop = 3/4)
train_data <- training(data_split)
test_data <- testing(data_split)
train_data %>% glimpse()
```

```{r}
flights_rec <-
  recipe(arr_delay ~ ., data = train_data) %>% 
  step_date(date, features = c("dow", "month")) %>% 
  step_holiday(date, holidays = timeDate::listHolidays("US")) %>% 
  step_rm(date) %>% 
  # Create dummy variables for all of the factor or character columns unless they are outcomes.
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  step_zv(all_predictors())
#flights_rec
```

```{r}
flights_workflow <- 
  workflow() %>% 
  add_model(logistic_reg() %>% set_engine("glm")) %>% 
  add_recipe(flights_rec)
flights_workflow
```

```{r}
flights_fit <- 
  flights_workflow %>% fit(data = train_data)
```

```{r}
flights_fit %>% 
  pull_workflow_fit() %>% 
  tidy()
```

```{r}
flights_pred <- 
  flights_fit %>%
    predict(test_data, type = "prob") %>% 
    bind_cols(test_data %>% select(arr_delay, time_hour, flight))
```

```{r}
flights_pred %>% 
  roc_curve(truth = arr_delay, event_level = "second", .pred_late) %>% 
  autoplot()
```


# Reticulate

```{r}
py_discover_config()
```

```{r}
py_config()
```


```{r eval=FALSE}
py_install(c(
  "scikit-learn",
  "matplotlib==3.2",
  "pandas"
))
```


```{r}
stopifnot(py_module_available("sklearn"))
stopifnot(py_module_available("pandas"))
```

```{python}
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.compose import make_column_transformer, make_column_selector
```

```{python}
train_data = r.train_data
y_train = train_data['arr_delay']
X_train = train_data.drop('arr_delay', axis=1)
```

```{python}
transformer = make_column_transformer(
  (StandardScaler(), make_column_selector(dtype_include=np.number)),
  remainder='drop')

pipeline = make_pipeline(
  transformer,
  LogisticRegression()
)
pipeline.fit(X_train, y_train)
```

```{python}
test_data = r.test_data
y_test = test_data['arr_delay']
X_test = test_data.drop('arr_delay', axis=1)
pipeline.score(X_test, y_test)
```

