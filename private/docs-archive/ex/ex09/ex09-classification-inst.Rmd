---
title: "Guided Exercise 09 - Classification"
output: 
  tufte::tufte_html:
    css: ../ex.css
    tufte_variant: "envisioned"
    highlight: pygments
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = "")
library(tidyverse)
theme_set(theme_bw())
```

The goal of this exercise is to practice with metrics of classifier performance.

## Getting started

We'll start today with an interactive activity.

> [Attacking discrimination with smarter machine learning](http://research.google.com/bigpicture/attacking-discrimination-in-ml/)

We'll focus today on the one-group example; we'll return to the part about blue vs orange groups later.

### Explore

Spend about 10 minutes playing with the "Threshold Decision" demonstration. Discuss the following questions with your partner:

1. What are the "scores"? What real-life concept does this capture? (Do you know your score?)

2. Why might a bank want to use "score" to decide whether to grant a loan? (Why don't banks grant all loan applications? Why do they ever grant loans?)

3. What sort of predictions are being made here? What constitutes a "correct" prediction?

4. Slowly sweep the threshold from 0 to 100. On scrap paper, sketch how Correct, True Positive Rate, and Positive Rate change as the threshold changes.

### Implement

Now let's implement those metrics ourselves to check our understanding.

```{r}
set.seed(0)
make_group_rand <- function(n, mean, sd, ...) {
  tibble(score = rnorm(n, mean = mean, sd = sd), ...)
}

# "Deterministic normal": for n points, we expect n * pnorm(x, mu, sd) of them to be below x.
make_group <- function(n, mean, sd, ...) {
  tibble(score = 0:100) %>% 
    mutate(n = floor(n * pnorm(score, mean, sd))) %>% 
    mutate(delta = c(diff(n), 0)) %>% 
    uncount(delta) %>% 
    select(score) %>% 
    mutate(...)
}

people <- bind_rows(
  make_group(150, 60, 10, repay = TRUE),
  make_group(150, 40, 10, repay = FALSE)
)
```

```{r}
ggplot(people, aes(x = score, fill = repay)) +
  geom_dotplot(binwidth = 5, dotsize = .5, binpositions = "all", method = "histodot", stackgroups = TRUE)
```

In your RStudio, find `ex09-classification.Rmd` and Run All. Look at the `people` data frame and make sure you
understand what it is and how it relates to the data in the web demonstration.

Also, study the following to understand how it works:

```{r}
people %>% 
  summarize(num_repayed = sum(repay),
            frac_repayed = mean(repay))
```


::: {.exercises}

1. Add a new column, `granted`, to the `people` dataframe that indicates if the
   bank grants the loan. Like the website, grant a loan if the score exceeds some fixed `threshold`.
   (Use a threshold that results in all 4 colors being visible; it's especially visible in the Positive Rate pie.)
   Save the results in `decisions`.

```{r echo=FALSE}
threshold <- 64
decisions <- 
  people %>% 
  mutate(granted = score >= threshold)
```

2. Compute the Positive Rate and the True Positive Rate, and Correctness. (Use `summarize` and perhaps `filter` on the `decisions`.)
   Check all of your results against the webapp; the numbers should be close although they may differ slightly because the data was not constructed identically.

```{r include=FALSE}
# Positive rate:
decisions %>% 
  summarize(mean(granted))

#True positive rate:
decisions %>% 
  filter(repay) %>% 
  summarize(mean(granted))
```

3. Compute the sensitivity and specificity. You may consult the [Wikipedia Page](https://en.wikipedia.org/wiki/Sensitivity_and_specificity#Confusion_matrix) if it's helpful. (Have you already computed one of these?) Discuss with your partner what "sensitivity" and "specificity" mean in this scenario.

```{r include=FALSE}
decisions %>% 
  summarize(
    true_positive_rate = sum(granted & repay) / sum(repay),    # frac of positives that were correct
    true_negative_rate = sum(!granted & !repay) / sum(!repay), # frac of negatives that were correct
    false_positive_rate = sum(granted & !repay) / sum(!repay)    # frac of negatives that were incorrect
  )
```


4. Add a column to `decisions` called `outcome` that gives a label to each decision as a "True Positive", "False Positive", etc. Use `case_when` with conditions like `repay & !granted`. Count how many of each outcome occurs at your current threshold.

```{r include=FALSE}
outcomes <- 
  decisions %>% 
    mutate(
      correct = repay == granted,
      outcome = case_when(
        repay & granted ~ "True Positive",
        repay & !granted ~ "False Negative",
        !repay & granted ~ "False Positive",
        !repay & !granted ~ "True Negative"
      )
    )
outcomes %>% 
  summarize(mean(correct))

outcome_counts <- outcomes %>% 
  group_by(outcome) %>% 
  summarize(n = n())
outcome_counts
```

5. Adjust the `threshold` to maximize the Correct rate. What is the True Positive Rate then? What trade-off do we have to make if we want to maximize True Positive Rate instead?

6. *bonus*: Create the following plot. You will need `expand_grid(threshold = 1:100)`.

```{r echo=FALSE}
all_decisions <- 
  people %>% 
    expand_grid(threshold = 1:100) %>% 
    mutate(granted = score >= threshold)

outcomes_wide <- 
all_decisions %>% 
  group_by(threshold) %>% 
  summarize(
    positive_rate = mean(granted),
    true_positive_rate = sum(granted & repay) / sum(repay),
    sensitivity = true_positive_rate,
    true_negative_rate = sum(!granted & !repay) / sum(!repay),
    specificity = true_negative_rate,
    false_positive_rate = 1 - specificity,
    correct = mean(granted == repay))

outcomes_wide %>% 
  pivot_longer(c(positive_rate, true_positive_rate, correct)) %>% 
  ggplot(aes(x = threshold, y = value, color = name)) + geom_line()
```

```{r roc-curve, include=FALSE}
outcomes_wide %>% 
  ggplot(aes(x = false_positive_rate, y = true_positive_rate)) +
  geom_line() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed")
```


:::
