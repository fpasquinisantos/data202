# Ethics and Social Impact

## Privacy and Surveillance Discussion: Reidentification and Facial Recognition

Data about people inevitably brings up questions about privacy and surveillance.
While the word "surveillance" may conjure images of security cameras and hidden
microphones, today all kinds of organizations are collecting data on us through
digital devices of all kinds--some in our pockets or living rooms.

Even for those who "have nothing to hide", this sort of surveillance is concerning.

As data scientists, analysts, and decision-makers, you will be faced with the
opportunity and challenge of handling data about people. You may decide what
data to collect, how to store it, how to share it, and how to use it. "Acting justly"
with this data requires thinking about, among other things, the right and
responsibility of privacy.

Pick one of the following two topics (Reidentification or Face Recognition) for this Discussion. Then:

1. Pick an article or video to engage with.
2. Write and post your observations and questions. Things you might mention:
    -   a one-sentence summary of the article for your future self
    -   a quote and your thoughts about it
    -   something you found surprising or cool
    -   something you disagree with
    -   something you didn't understand
    -   a question this raises for you
3. Read what your peers wrote about the other topic.

### Reidentification

Suppose your organization is asked to share data it has collected about individual people.
You might think that removing the names is enough to protect privacy. Is it?

Read this overview: <https://georgetownlawtechreview.org/re-identification-of-anonymized-data/GLTR-04-2017/>. Focus on sections 1 (Introduction), IV (Re-identification), and V (Conclusion).

If you want to go deeper (or watch a video):

-   Watch the video on ***[this page](https://queue.acm.org/detail.cfm?id=2838930)*** for an example of the kind of concerns that come up when trying to anonymize data.
-   Bonus: read ***[Sweeny\'s original paper](https://dataprivacylab.org/projects/identifiability/paper1.pdf)*** for context

### Face Recognition

Face recognition is useful to people: auto-tagging on social media and photo apps, unlocking
your phone, convenience in boarding planes or paying for stuff. And it's useful
to business and government: tracking customer behavior in stores, finding criminals,
identifying people critical of the government, etc... and many people think that
some of these uses cross an ethical line. There is also evidence that many 
facial recognition systems perform more poorly for some groups of people, hence
increasing the risk of harm to them. Others think that the potential for
harm or abuse makes facial recognition technology something that should not be
deployed even if it were perfectly accurate.

Face recognition technology has recently gained more visibility as companies
like Facebook have [announced they're discontinuing some forms of face recognition](https://about.fb.com/news/2021/11/update-on-use-of-face-recognition/).

Our question:

**How might facial recognition technology be useful? how might it be harmful?**

##### Articles or Videos

-   [GenderShades](http://gendershades.org/index.html) summary video
-   Project Green Light (Detroit)
    -   Tawana Petty Interview (second video on [this page](https://esc.umich.edu/project-green-light/))---if you watch this, a second reading is optional
    -   Hill, K. (2020, July 24). [Wrongfully Accused By an Algorithm](https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html). The New York Times.\
-   Portland\'s facial recognition ordinance: coverage by [The Hill](https://thehill-com.cdn.ampproject.org/c/s/thehill.com/policy/technology/515772-portland-adopts-landmark-facial-recognition-ordinance?amp)
-   <https://www.nytimes.com/2019/07/10/opinion/facial-recognition-race.html>

Going deeper:

- The 2021 film [Coded Bias](https://www.codedbias.com/) is feature-length discussion of facial recognition and related issues.
  - The IndieLens [discussion guide](https://independentlens.s3.amazonaws.com/2200/10%20Coded%20Bias/Indie%20Lens%20Pop-Up/CODEDBIAS_DiscussionGuide.pdf) has
    a lot of summary information, background, and references.
- See the UMich ESC [Project Green Light](https://esc.umich.edu/project-green-light/) site for some other articles.


## Background

* Fundamentals of Ethics: do the Integrated Ethics Labs [First Look at Ethics](https://integratedethicslabs.org/labs/first-look/first-look-worksheet/) exercise.

* [MDSR2e chapter on Ethics](https://mdsr-book.github.io/mdsr2e/ch-ethics.html)
* [ACM Select on Algorithmic Fairness](https://selects.acm.org/selections/why-algorithmic-fairness)
* <https://blogs.rstudio.com/ai/posts/2021-07-15-ai-fairness/>

### Current Issues

* [Montreal AI Ethics Brief](https://brief.montrealethics.ai/)
* AlgorithmWatch
